{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b434ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import heapq\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07931222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'movielens'\n",
    "algorithm = 'gcn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba94016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /Users/johnhannebery/gitrepos/recsys/Data/movielens\n",
      "Embed path: /Users/johnhannebery/gitrepos/recsys/embeds/movielens/gcn\n",
      "Plots path: /Users/johnhannebery/gitrepos/recsys/plots/movielens\n",
      "Score path: /Users/johnhannebery/gitrepos/recsys/scores/movielens/gcn\n",
      "Results path: /Users/johnhannebery/gitrepos/recsys/results/movielens/gcn\n"
     ]
    }
   ],
   "source": [
    "ds_path = os.path.join(os.getcwd(), f'Data/{dataset}')\n",
    "embed_path = os.path.join(os.getcwd(), f'embeds/{dataset}/{algorithm}')\n",
    "plot_path = os.path.join(os.getcwd(), f'plots/{dataset}')\n",
    "scores_path = os.path.join(os.getcwd(), f'scores/{dataset}/{algorithm}')\n",
    "results_path = os.path.join(os.getcwd(), f'results/{dataset}/{algorithm}')\n",
    "print(\"Dataset path:\", ds_path)\n",
    "print(\"Embed path:\", embed_path)\n",
    "print(\"Plots path:\", plot_path)\n",
    "print(\"Score path:\", scores_path)\n",
    "print(\"Results path:\", results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8e8f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_ratings(file_name):\n",
    "    user_dict = dict()\n",
    "    inter_mat = list()\n",
    "\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for l in lines:\n",
    "        tmps = l.strip()\n",
    "        inters = [int(i) for i in tmps.split(' ')]\n",
    "\n",
    "        u_id, pos_ids = inters[0], inters[1:]\n",
    "        pos_ids = list(set(pos_ids))\n",
    "\n",
    "        for i_id in pos_ids:\n",
    "            inter_mat.append([u_id, i_id])\n",
    "\n",
    "        if len(pos_ids) > 0:\n",
    "            user_dict[u_id] = pos_ids\n",
    "    return np.array(inter_mat), user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c71163e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset != 'movielens':\n",
    "    train, train_user_dict = _load_ratings(os.path.join(ds_path,'train.txt'))\n",
    "    test, test_user_dict = _load_ratings(os.path.join(ds_path,'test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ee2d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'movielens':\n",
    "    cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "\n",
    "    df = pd.read_csv(os.path.join(ds_path,'u.data'),sep='\\t', names=cols)\n",
    "    df = df[df['rating']>=4]\n",
    "\n",
    "    df.rename(columns={'userId':'user_id', 'movieId':'item_id'},inplace=True)\n",
    "\n",
    "    df = df[['user_id', 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b59ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'movielens':\n",
    "    train, test = train_test_split(df, test_size=0.1, random_state=1234)\n",
    "else:\n",
    "    cols = ['user_id', 'item_id']\n",
    "    train = pd.DataFrame(train, columns = cols)\n",
    "    test = pd.DataFrame(test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f67863fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['user_id'].isin(train['user_id'].tolist())]\n",
    "test = test[test['item_id'].isin(train['item_id'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "418220c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/johnhannebery/gitrepos/recsys/embeds/movielens/gcn'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "99ac9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed = pd.read_csv(os.path.join(embed_path,'user_embed.csv'))\n",
    "if algorithm == 'kgat':\n",
    "    item_embed = pd.read_csv(os.path.join(embed_path,'entity_embed.csv'))\n",
    "else:\n",
    "    item_embed = pd.read_csv(os.path.join(embed_path,'item_embed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5abd12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read scores\n",
    "scores_df = pd.read_csv(os.path.join(scores_path,'scores_df.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b735fc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555385</td>\n",
       "      <td>428</td>\n",
       "      <td>313</td>\n",
       "      <td>12.460766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>445460</td>\n",
       "      <td>748</td>\n",
       "      <td>50</td>\n",
       "      <td>12.120422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>555114</td>\n",
       "      <td>428</td>\n",
       "      <td>300</td>\n",
       "      <td>11.930076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>977000</td>\n",
       "      <td>519</td>\n",
       "      <td>1612</td>\n",
       "      <td>11.883427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666420</td>\n",
       "      <td>507</td>\n",
       "      <td>300</td>\n",
       "      <td>11.832407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18835</th>\n",
       "      <td>636462</td>\n",
       "      <td>286</td>\n",
       "      <td>172</td>\n",
       "      <td>3.864752</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18836</th>\n",
       "      <td>636901</td>\n",
       "      <td>286</td>\n",
       "      <td>781</td>\n",
       "      <td>3.854414</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837</th>\n",
       "      <td>636575</td>\n",
       "      <td>286</td>\n",
       "      <td>269</td>\n",
       "      <td>3.827556</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>836764</td>\n",
       "      <td>914</td>\n",
       "      <td>1041</td>\n",
       "      <td>3.791851</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18839</th>\n",
       "      <td>836258</td>\n",
       "      <td>914</td>\n",
       "      <td>216</td>\n",
       "      <td>3.756467</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  user_id  item_id      score  rank\n",
       "0          555385      428      313  12.460766     1\n",
       "1          445460      748       50  12.120422     1\n",
       "2          555114      428      300  11.930076     2\n",
       "3          977000      519     1612  11.883427     1\n",
       "4          666420      507      300  11.832407     1\n",
       "...           ...      ...      ...        ...   ...\n",
       "18835      636462      286      172   3.864752    18\n",
       "18836      636901      286      781   3.854414    19\n",
       "18837      636575      286      269   3.827556    20\n",
       "18838      836764      914     1041   3.791851    19\n",
       "18839      836258      914      216   3.756467    20\n",
       "\n",
       "[18840 rows x 5 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "561598e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = train.groupby('item_id', as_index = False).agg({'user_id':'count'}).rename(columns={'user_id':'n_ratings'})\n",
    "item_counts['novelty'] = -np.log2(item_counts['n_ratings'] / train['user_id'].nunique())\n",
    "\n",
    "class metrics():\n",
    "  \n",
    "  @staticmethod\n",
    "  def dcg_at_k(r, k, method: int =1) -> float:\n",
    "    r_k = np.asfarray(r)[:k]\n",
    "    if r_k.size:\n",
    "        if method == 0:\n",
    "            return r_k[0] + np.sum(r_k[1:] / np.log2(np.arange(2, r_k.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r_k / np.log2(np.arange(2, r_k.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0\n",
    "\n",
    "class Metrics():\n",
    "  \n",
    "  def __init__(self, r: list, k: int, all_pos_num: int):\n",
    "    self.r = r\n",
    "    self.k = k\n",
    "    self.all_pos_num = all_pos_num\n",
    "  \n",
    "  def precision_at_k(self) -> float:\n",
    "      r_k = np.asarray(self.r)[:self.k]\n",
    "      return np.mean(r_k)\n",
    "\n",
    "\n",
    "  def dcg_at_k(self, reverse_r = False, method: int = 1) -> float:\n",
    "      if reverse_r == True:\n",
    "        r_k = np.asfarray(sorted(self.r, reverse=True))[:self.k]\n",
    "      else:\n",
    "        r_k = np.asfarray(self.r)[:self.k]\n",
    "      if r_k.size:\n",
    "          if method == 0:\n",
    "              return r_k[0] + np.sum(r_k[1:] / np.log2(np.arange(2, r_k.size + 1)))\n",
    "          elif method == 1:\n",
    "              return np.sum(r_k / np.log2(np.arange(2, r_k.size + 2)))\n",
    "          else:\n",
    "              raise ValueError('method must be 0 or 1.')\n",
    "      return 0\n",
    "\n",
    "\n",
    "#   def ndcg_at_k(self, method: int = 1, reverse_r = True) -> float:\n",
    "#       dcg_max = self.dcg_at_k(reverse_r = reverse_r, method = method)\n",
    "#       if not dcg_max:\n",
    "#           return 0.\n",
    "#       return self.dcg_at_k(self.r, self.k, method) / dcg_max\n",
    "    \n",
    "  def ndcg_at_k(self, method: int = 1) -> float:\n",
    "      dcg_max = metrics.dcg_at_k(sorted(self.r, reverse=True), self.k, method)\n",
    "      if not dcg_max:\n",
    "          return 0.\n",
    "      return metrics.dcg_at_k(self.r, self.k, method) / dcg_max\n",
    "\n",
    "\n",
    "  def recall_at_k(self) -> float:\n",
    "      r_k = np.asfarray(self.r)[:self.k]\n",
    "      return np.sum(r_k) / self.all_pos_num\n",
    "\n",
    "\n",
    "  def hit_at_k(self) -> float:\n",
    "      r_k = np.array(self.r)[:self.k]\n",
    "      if np.sum(r_k) > 0:\n",
    "          return 1.\n",
    "      else:\n",
    "          return 0.\n",
    "        \n",
    "  @staticmethod\n",
    "  def F1(pre: float, rec: float) -> float:\n",
    "      if pre + rec > 0:\n",
    "          return (2.0 * pre * rec) / (pre + rec)\n",
    "      else:\n",
    "          return 0.\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def calculate_diversity(item_ids, item_embed):\n",
    "  if len(item_ids) == 1:\n",
    "    return 1\n",
    "  \n",
    "  div = 0\n",
    "  n_items = len(item_ids)\n",
    "  \n",
    "  df_embed = item_embed[item_embed['item_id'].isin(item_ids)]\n",
    "  \n",
    "  np_embed = np.array(df_embed.drop(columns='item_id'))\n",
    "  \n",
    "  \n",
    "  for embed_index in range(n_items):\n",
    "    for embed_index_2 in range(n_items):\n",
    "      if embed_index != embed_index_2:\n",
    "        div += np.linalg.norm(np_embed[embed_index] - np_embed[embed_index_2])\n",
    "        \n",
    "  div /= n_items * (n_items-1)\n",
    "  \n",
    "  return div\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def calculate_novelty(item_ids):\n",
    "  n_items = len(item_ids)\n",
    "  \n",
    "  df_novelty = item_counts[item_counts['item_id'].isin(item_ids)]\n",
    "  \n",
    "  nov = np.sum(df_novelty['novelty'])\n",
    "  \n",
    "  nov /= n_items\n",
    "  \n",
    "  return nov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c6275ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = [1, 5, 10, 20]\n",
    "\n",
    "\n",
    "def test_all_users(test_df, scores, user_embed, item_embed):\n",
    "    \n",
    "    result_append = []\n",
    "    result = []\n",
    "    \n",
    "    recset = set()\n",
    "    reclist = []\n",
    "\n",
    "    coverage_dict_set = {i:set() for i in Ks}\n",
    "    coverage_dict_list = {i:list() for i in Ks}\n",
    "\n",
    "    testset = set()\n",
    "\n",
    "    result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "              'hit_ratio': np.zeros(len(Ks)), 'F1': np.zeros(len(Ks)), 'diversity': np.zeros(len(Ks)), 'novelty': np.zeros(len(Ks)), 'coverage': np.zeros(len(Ks))}\n",
    "\n",
    "    test_users = test_df['user_id'].unique().tolist()\n",
    "\n",
    "    test_items = item_embed['item_id'].tolist()\n",
    "\n",
    "    testset.update(test_items)\n",
    "\n",
    "    for u in test_users:\n",
    "        precision, recall, ndcg, hit_ratio, F1, diversity, novelty = [], [], [], [], [], [], []\n",
    "        r = []\n",
    "        user_pos_test = test_df[test_df['user_id']==u]['item_id'].tolist()\n",
    "        K_max_item_score = scores[scores['user_id']==u]['item_id'].tolist()[:20]\n",
    "        \n",
    "        for i in K_max_item_score:\n",
    "            reclist.append(i)\n",
    "            if i in user_pos_test:\n",
    "                r.append(1)\n",
    "            else:\n",
    "                r.append(0)\n",
    "                \n",
    "                \n",
    "        for K in Ks:\n",
    "        \n",
    "            metric_K = Metrics(r, K, len(user_pos_test))\n",
    "\n",
    "            precision.append(metric_K.precision_at_k())\n",
    "            recall.append(metric_K.recall_at_k())\n",
    "            ndcg.append(metric_K.ndcg_at_k())\n",
    "            hit_ratio.append(metric_K.hit_at_k())\n",
    "            F1.append(metric_K.F1(metric_K.precision_at_k(), metric_K.recall_at_k()))\n",
    "            diversity.append(calculate_diversity(K_max_item_score[:K], item_embed))\n",
    "            novelty.append(calculate_novelty(K_max_item_score[:K]))\n",
    "            coverage_dict_list[K].extend(K_max_item_score[:K])\n",
    "        \n",
    "        result_append.append({'recall': np.array(recall), 'precision': np.array(precision),\n",
    "                'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio), 'F1': np.array(F1), \n",
    "                       'diversity': np.array(diversity), 'novelty': np.array(novelty)})\n",
    "        \n",
    "    for re in result_append:\n",
    "      result['precision'] += re['precision']/len(test_users)\n",
    "      result['recall'] += re['recall']/len(test_users)\n",
    "      result['ndcg'] += re['ndcg']/len(test_users)\n",
    "      result['hit_ratio'] += re['hit_ratio']/len(test_users)\n",
    "      result['F1'] += re['F1']/len(test_users)\n",
    "      result['diversity'] += re['diversity']/len(test_users)\n",
    "      result['novelty'] += re['novelty']/len(test_users)\n",
    "    \n",
    "    recset.update(reclist)\n",
    "  \n",
    "    for i,K in enumerate(Ks):\n",
    "        coverage_dict_set[K].update(coverage_dict_list[K])\n",
    "        result['coverage'][i] = len(coverage_dict_set[K]) / len(testset)\n",
    "\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df['K'] = Ks\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d88d398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.0\n",
      "54.799999999999955\n"
     ]
    }
   ],
   "source": [
    "#Split into high and low activity groups\n",
    "user_counts_data = train.groupby('user_id',as_index=False).agg({'item_id':'count'}).rename(columns={'item_id':'count'})\n",
    "item_counts_data = train.groupby('item_id',as_index=False).agg({'user_id':'count'}).rename(columns={'user_id':'count'})\n",
    "\n",
    "user_cutoff = user_counts_data['count'].quantile(0.8)\n",
    "print(user_cutoff)\n",
    "\n",
    "item_cutoff = item_counts_data['count'].quantile(0.8)\n",
    "print(item_cutoff)\n",
    "\n",
    "user_low_activity = user_counts_data[user_counts_data['count'] <= user_cutoff]['user_id'].tolist()\n",
    "\n",
    "item_low_activity = item_counts_data[item_counts_data['count'] <= item_cutoff]['item_id'].tolist()\n",
    "\n",
    "user_low_activity_test = test[test['user_id'].isin(user_low_activity)]\n",
    "user_high_activity_test = test[~test['user_id'].isin(user_low_activity)]\n",
    "\n",
    "item_low_activity_test = test[test['user_id'].isin(item_low_activity)]\n",
    "item_high_activity_test = test[~test['user_id'].isin(item_low_activity)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91e04d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.086740016937256\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_all = test_all_users(test, scores_df, user_embed, item_embed)\n",
    "print(time.time() - t1)\n",
    "results_all.to_csv(os.path.join(results_path,'results_all.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b4e5de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.289842128753662\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_low_user = test_all_users(user_low_activity_test, scores_df, user_embed, item_embed)\n",
    "print(time.time() - t1)\n",
    "results_low_user.to_csv(os.path.join(results_path,'results_low_user.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35db4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8882946968078613\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_high_user = test_all_users(user_high_activity_test, scores_df, user_embed, item_embed)\n",
    "print(time.time() - t1)\n",
    "results_high_user.to_csv(os.path.join(results_path,'results_high_user.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0bd7835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.702528953552246\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_low_item = test_all_users(item_low_activity_test, scores_df, user_embed, item_embed)\n",
    "print(time.time() - t1)\n",
    "results_low_item.to_csv(os.path.join(results_path,'results_low_item.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8862be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3516180515289307\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_high_item = test_all_users(item_high_activity_test, scores_df, user_embed, item_embed)\n",
    "print(time.time() - t1)\n",
    "results_high_item.to_csv(os.path.join(results_path,'results_high_item.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
